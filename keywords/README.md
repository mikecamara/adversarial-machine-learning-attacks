
## adversarial machine learning

dblp - 276 matches

### Found


* [Securing Connected & Autonomous Vehicles: Challenges Posed by Adversarial Machine Learning and the Way Forward (2020)](https://ieeexplore.ieee.org/document/9003212)

  This paper present an in-depth overview of the various challenges associated with the application of ML in vehicular networks. 

<hr>

## Adversarial Robustness Toolbox autonomous vehicles

### Found

- [Teaching Adversarial Machine Learning (2020)](https://dl.acm.org/doi/pdf/10.1145/3368308.3415381)

<hrr>

## Topic
safety Analysis of Autonomous Vehicle Systems Software

## First paper
Attack and Fault Injection in Self-driving Agents on the Carla Simulator – Experience Report

### Keywords: 
Self-driving, Machine Learning,Trained agent,Adversarial
attacks,Faults, Injection,Simulation

### Goal 
This paper reports an experimental campaign on the injection
of adversarial attacks and software faults in a self-driving agent running in a driving simulator.

### RQs
- Reusing existing tools they experiment
and discuss on the risk of adversarial attacks and software faults for an end2end selfdriving agent
- no works experimented with end2end self-driving agents including both
faults and attacks perspectives
- this experience report provides a guide as
well as practical evidence of a method easy-to-implement that allows to rapidly deploy
tests for self-driving agents under various adversarial attacks and faulty conditions,
in an entirely simulated (and reproducible) environment.
-  the paper
explains how to configure, inject and ultimately collect evidences of the effects of attacks
and faults injected.
- show how to manipulate a driving simulator to perform the
experiments and to execute the experimental campaign

### References
1. Dosovitskiy, A.: et al.: CARLA: an open urban driving simulator. In: Conference on Robot
Learning, pp. 1–16 (2017)
2. Unreal Engine. www.unrealengine.com [online]
3. Chen, D., et al.: Learning by Cheating. In: Conference on Robot Learning (CoRL) (2019)
4. Secci, F., Ceccarelli, A.: On failures of RGB cameras and their effects in autonomous driving
applications. In: ISSRE, pp. 13–24 (2020)
5. Kumar, K.N., et al.: Black-box adversarial attacks in autonomous vehicle technology. arXiv
e-prints 2101.06092 (2021).
6. Integration of ART and LbC. https://github.com/piazzesiNiccolo/myLbc [online]
7. Deng, Y., et al.: An analysis of adversarial attacks and defenses on autonomous driving models.
In: IEEE International Conference on Pervasive Computing and Communications (PerCom)
(2020)
8. Nicolae, M.I., et al.: Adversarial Robustness Toolbox v1.0.0. arXiv preprint arXiv:1807.010
69v4 (2019)
9. Zablocki, É., et al.: Explainability of vision-based autonomous driving systems: review and
challenges. arXiv preprint arXiv:2101.05307 (2021)
10. Engstrom, L., Tran, B., Tsipras, D., Schmidt, L., Madry, A.: Exploring the Landscape of
Spatial Robustness. In: PMLR 2019 (2019)
11. Chen, J., Jordan,M.I.,Wainwright,M.J.: Hopskipjumpattack: a query-efficient decision-based
attack. In: IEEE Symposium on Security and Privacy (SP) (2020)
12. Kurakin, A., Goodfellow, I., Bengio, S.: Adversarial examples in the physical world. arXiv:
1607.02533 (2016)
13. Jang, U., Wu, X., Jha, S.: Objective metrics and gradient descent algorithms for adversarial
examples in machine learning. In: ACSAC 2017 (2017)
14. ART documentation v1.5.1. https://adversarial-robustness-toolbox.readthedocs.io/en/latest/
15. Goodfellow, I.J., Shlens, J., Szegedy, C.: Explaining and harnessing adversarial examples. arXiv preprint arXiv:1412.6572 (2014)
16. Brown, T.B., et al.: Adversarial patch." arXiv preprint arXiv:1712.09665 (2017)
17. Kurakin, A., Goodfellow, I., Bengio, S.: Adversarial examples in the physical world. arXiv
preprint. https://arxiv.org/abs/1607.02533 (2016)
18. Stevens, E., Antiga, L., Viehmann, T.: Deep Learning with PyTorch. Manning Publications
Company, Shelter Island (2020)
19. Codevilla, F., et al.: Exploring the limitations of behavior cloning for autonomous driving.
In: Proceedings of the IEEE/CVF International Conference on Computer Vision (2019)
Attack and Fault Injection in Self-driving Agents 225
20. Grigorescu, S., et al.: A survey of deep learning techniques for autonomous driving. J. Field
Robot. 37(3), 362–386 (2020)
21. Miller, C.: Lessons learned from hacking a car. IEEE Des. Test 36, 6 (2019)
22. Ackerman, E.: Three small stickers in intersection can cause tesla autopilot to swerve into
wrong lane. IEEE Spectrum (2019)
23. Condia, J., et al.: FlexGripPlus: an improved GPGPU model to support reliability analysis. Microelect. Reliab. 109, 1–14 (2020)
24. Mahmoud, A., et al.: Pytorchfi: a runtime perturbation tool for DNNS. In: IEEE/IFIP
International Conference on Dependable Systems and Networks Workshops (DSN-W) (2020)
25. Li, G., et al.: Understanding error propagation in deep learning neural network (DNN) accelerators and applications. In: International Conference for High Performance Computing,
Networking, Storage and Analysis (SC) (2017)
26. Du, X., Xiaoting, G., Sui, Y.: Fault triggers in the tensorflow framework: an experience report.
In: IEEE International Symposium on Software Reliability Engineering (ISSRE) (2020)
27. Jha, S., Banerjee, S., Cyriac, J., Kalbarczyk, Z.T., Iyer, R. K.: AVFI: fault Injection for
autonomous vehicles. In: IEEE/IFIP International Conference on Dependable Systems and
Networks Workshops (DSN-W), pp. 55–56 (2018)
28. Jha, S., et al.: Kayotee: A fault injection-based system to assess the safety and reliability of
autonomous vehicles to faults and errors. arXiv preprint arXiv:1907.01024 (2019)
29. Zhang, J.M., et al.: Machine learning testing: Survey, landscapes and horizons. In: IEEE
Transactions on Software Engineering (2020)
30. Chen, D.: Learning by cheating code. https://github.com/dotchen/LearningByCheating
31. Pytorchfi documentation. https://pytorchfi.github.io/core/declare-fi
32. Zoppi, T., et al.: Unsupervised anomaly detectors to ddetect intrusions in the current threat
landscape. ACM/IMS Trans. Data Sci. 2(2), 7 (2021)